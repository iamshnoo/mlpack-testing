{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cross Entropy Loss",
      "provenance": [],
      "collapsed_sections": [
        "SLU_VSKKzXjC",
        "PQRpXdvaLOEm",
        "xKB9xRZ718-D",
        "LKi5hbH72U-M",
        "8OScE3xX2LKZ",
        "sICTsZY52HVM",
        "lemQO_bh2BCO",
        "LNsiV5fb2Yhs",
        "xJm51GeT3V5P",
        "7VrlgN3k3S62",
        "Bfdhz8Xs3S63",
        "2qUv4wF-3S68",
        "jZmwY3j-3S6_",
        "OmMgyLrh3S7D"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY7SCBqn4rG5",
        "colab_type": "text"
      },
      "source": [
        "# CrossEntropy Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLU_VSKKzXjC",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "`CrossEntropyError` of **mlpack** is actually `BCELoss` of **PyTorch** and works only when target is one-hot encoded and calculates reduction='sum' by default whereas PyTorch calculates reduction='mean' by default. Also the mlpack implementation doesn't currently support weights, for which #2368 by @kartikdutt18 is currently open. Also, none of these assumptions are written anywhere, inspite of the discussion in #1070 which was merged a long time back.\n",
        "\n",
        "Also the Reconstruction Loss of mlpack basically does the exact same thing as this, though maybe it calculates reduction='mean' by default.\n",
        "\n",
        "---\n",
        "\n",
        "### General equation of cross entropy loss for multi-class scenario with C classes\n",
        "\n",
        "![alt text](https://latex.codecogs.com/gif.latex?CE&space;=&space;-\\sum_{i}^{C}t_{i}&space;log&space;(s_{i}))\n",
        "\n",
        "Where \n",
        "ti and si are the groundtruth and the CNN score for each class i in C\n",
        "\n",
        "---\n",
        "\n",
        "### Specific equation of the loss function for a binary classification scenario with 2 classes only used in the mlpack implementation\n",
        "\n",
        "![Equation](https://latex.codecogs.com/gif.latex?CE&space;=&space;-\\sum_{i=1}^{C%27=2}t_{i}&space;log&space;(s_{i})&space;=&space;-t_{1}&space;log(s_{1})&space;-&space;(1&space;-&space;t_{1})&space;log(1&space;-&space;s_{1}))\n",
        "\n",
        "---\n",
        "\n",
        "### Assumptions made by the PyTorch implementation of BCELoss\n",
        "\n",
        "Assertion `x >= 0. && x <= 1.' ensures each input value should be between 0~1. <br>\n",
        "Also, each value of label can be either 0 or 1 (one-hot encoded).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQRpXdvaLOEm",
        "colab_type": "text"
      },
      "source": [
        "### Imports and installation of mlpack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS_tm4kdK0Zi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!sudo apt-get install libmlpack-dev \n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKB9xRZ718-D",
        "colab_type": "text"
      },
      "source": [
        "## 2 classes (Demonstrates that it works for Binary classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKi5hbH72U-M",
        "colab_type": "text"
      },
      "source": [
        "### PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OScE3xX2LKZ",
        "colab_type": "text"
      },
      "source": [
        "#### None Reduction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPLoDAVC2N3F",
        "colab_type": "code",
        "outputId": "2440f262-87d4-48ad-e8e1-b0517b99a7e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "loss = nn.BCELoss(reduction='none')\n",
        "input = torch.tensor([[ 0.1778,  0.1203],\n",
        "                      [ 0.0957,  0.2403],\n",
        "                      [ 0.1397,  0.1925], \n",
        "                      [ 0.2256, 0.3144]], requires_grad=True) # 4 Rows, 2 columns \n",
        "target = torch.tensor([[0., 1.],\n",
        "                       [1., 0.],\n",
        "                       [0., 0.],\n",
        "                       [1., 0.]])\n",
        "output = loss(input, target)\n",
        "output.backward(torch.ones(input.shape))\n",
        "print(\"Input : \")\n",
        "print(input)\n",
        "print(\"Target : \")\n",
        "print(target)\n",
        "print(\"FORWARD : \")\n",
        "print(\"Loss : \")\n",
        "print(output)\n",
        "print(\"BACKWARD : \")\n",
        "print(input.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : \n",
            "tensor([[0.1778, 0.1203],\n",
            "        [0.0957, 0.2403],\n",
            "        [0.1397, 0.1925],\n",
            "        [0.2256, 0.3144]], requires_grad=True)\n",
            "Target : \n",
            "tensor([[0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]])\n",
            "FORWARD : \n",
            "Loss : \n",
            "tensor([[0.1958, 2.1178],\n",
            "        [2.3465, 0.2748],\n",
            "        [0.1505, 0.2138],\n",
            "        [1.4890, 0.3775]], grad_fn=<BinaryCrossEntropyBackward>)\n",
            "BACKWARD : \n",
            "tensor([[  1.2162,  -8.3126],\n",
            "        [-10.4493,   1.3163],\n",
            "        [  1.1624,   1.2384],\n",
            "        [ -4.4326,   1.4586]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sICTsZY52HVM",
        "colab_type": "text"
      },
      "source": [
        "#### Sum Reduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53pTdB-9zUI4",
        "colab_type": "code",
        "outputId": "2ccc80b2-2b92-48ab-9245-4495f8173a87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "loss = nn.BCELoss(reduction='sum')\n",
        "input = torch.tensor([[ 0.1778,  0.1203],\n",
        "                      [ 0.0957,  0.2403],\n",
        "                      [ 0.1397,  0.1925], \n",
        "                      [ 0.2256, 0.3144]], requires_grad=True) # 4 Rows, 2 columns \n",
        "target = torch.tensor([[0., 1.],\n",
        "                       [1., 0.],\n",
        "                       [0., 0.],\n",
        "                       [1., 0.]])\n",
        "output = loss(input, target)\n",
        "output.backward()\n",
        "print(\"Input : \")\n",
        "print(input)\n",
        "print(\"Target : \")\n",
        "print(target)\n",
        "print(\"FORWARD : \")\n",
        "print(\"Loss : \")\n",
        "print(output)\n",
        "print(\"BACKWARD : \")\n",
        "print(input.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : \n",
            "tensor([[0.1778, 0.1203],\n",
            "        [0.0957, 0.2403],\n",
            "        [0.1397, 0.1925],\n",
            "        [0.2256, 0.3144]], requires_grad=True)\n",
            "Target : \n",
            "tensor([[0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]])\n",
            "FORWARD : \n",
            "Loss : \n",
            "tensor(7.1656, grad_fn=<BinaryCrossEntropyBackward>)\n",
            "BACKWARD : \n",
            "tensor([[  1.2162,  -8.3126],\n",
            "        [-10.4493,   1.3163],\n",
            "        [  1.1624,   1.2384],\n",
            "        [ -4.4326,   1.4586]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lemQO_bh2BCO",
        "colab_type": "text"
      },
      "source": [
        "#### Mean reduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E84DQhZu2KbW",
        "colab_type": "code",
        "outputId": "65b036a2-84fb-47d6-f44e-c81702b08775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "loss = nn.BCELoss(reduction='mean')\n",
        "input = torch.tensor([[ 0.1778,  0.1203],\n",
        "                      [ 0.0957,  0.2403],\n",
        "                      [ 0.1397,  0.1925], \n",
        "                      [ 0.2256, 0.3144]], requires_grad=True) # 4 Rows, 2 columns \n",
        "target = torch.tensor([[0., 1.],\n",
        "                       [1., 0.],\n",
        "                       [0., 0.],\n",
        "                       [1., 0.]])\n",
        "output = loss(input, target)\n",
        "output.backward()\n",
        "print(\"Input : \")\n",
        "print(input)\n",
        "print(\"Target : \")\n",
        "print(target)\n",
        "print(\"FORWARD : \")\n",
        "print(\"Loss : \")\n",
        "print(output)\n",
        "print(\"BACKWARD : \")\n",
        "print(input.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : \n",
            "tensor([[0.1778, 0.1203],\n",
            "        [0.0957, 0.2403],\n",
            "        [0.1397, 0.1925],\n",
            "        [0.2256, 0.3144]], requires_grad=True)\n",
            "Target : \n",
            "tensor([[0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]])\n",
            "FORWARD : \n",
            "Loss : \n",
            "tensor(0.8957, grad_fn=<BinaryCrossEntropyBackward>)\n",
            "BACKWARD : \n",
            "tensor([[ 0.1520, -1.0391],\n",
            "        [-1.3062,  0.1645],\n",
            "        [ 0.1453,  0.1548],\n",
            "        [-0.5541,  0.1823]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNsiV5fb2Yhs",
        "colab_type": "text"
      },
      "source": [
        "### mlpack\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ3t6bCtDemV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "%%writefile test.cpp  \n",
        "\n",
        "// This uses the computations present in cross_entropy_error_impl.hpp in ann/loss_functions.\n",
        "#include <iostream>\n",
        "#include <armadillo>\n",
        "\n",
        "using namespace std;\n",
        "using namespace arma;\n",
        "\n",
        "int main()\n",
        "{\n",
        "  // Constructor\n",
        "  arma::mat x,y;\n",
        "  arma::mat weight;\n",
        "\n",
        "  x << 0.1778 << 0.1203 << endr\n",
        "    << 0.0957 << 0.2403 << endr\n",
        "    << 0.1397 << 0.1925 << endr\n",
        "    << 0.2256 << 0.3144 << endr;\n",
        "\n",
        "  y << 0 << 1 << endr\n",
        "    << 1 << 0 << endr\n",
        "    << 0 << 0 << endr\n",
        "    << 1 << 0 << endr;\n",
        "\n",
        "  // Forward\n",
        "  const double eps = 1e-10;\n",
        "  arma::mat loss_none = -(y % arma::log(x + eps) + (1. - y) % arma::log(1. - x + eps));\n",
        "  double loss_sum = arma::accu(loss_none);\n",
        "  double loss_mean = loss_sum / x.n_elem;\n",
        "\n",
        "  // Backward\n",
        "  arma::mat output;\n",
        "  output = (1. - y) / (1. - x + eps) - y / (x + eps);\n",
        "\n",
        "  // Display\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  cout << \"USER-PROVIDED MATRICES : \" << endl;\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  cout << \"Input shape : \"<< x.n_rows << \" \" << x.n_cols << endl;\n",
        "  cout << \"Input : \" << endl << x << endl;\n",
        "  cout << \"Target shape : \"<< y.n_rows << \" \" << y.n_cols << endl;\n",
        "  cout << \"Target : \" << endl << y << endl;\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  cout << \"SUM \" << endl;\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  cout << \"FORWARD : \" << endl;\n",
        "  cout << \"Loss : \\n\" << loss_none << '\\n';\n",
        "  cout << \"Loss (sum):\\n\" << loss_sum << '\\n';\n",
        "  cout << \"BACKWARD : \" << endl;\n",
        "  cout << \"Output shape : \"<< output.n_rows << \" \" << output.n_cols << endl;\n",
        "  cout << \"Output (sum) : \" << endl << output << endl;\n",
        "  cout << \"Sum of all values in this matrix : \" << arma::as_scalar(arma::accu(output)) << endl;\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  cout << \"MEAN \" << endl;\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  cout << \"FORWARD : \" << endl;\n",
        "  cout << \"Loss (mean):\\n\" << loss_mean << '\\n';\n",
        "  cout << \"BACKWARD : \" << endl;\n",
        "  cout << \"Output shape : \"<< output.n_rows << \" \" << output.n_cols << endl;\n",
        "  cout << \"Output (mean) : \" << endl << output / x.n_elem << endl;\n",
        "  cout << \"Sum of all values in this matrix : \" << arma::as_scalar(arma::accu(output / x.n_elem)) << endl;\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  return 0;                                            \n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46gpKSjcDe4e",
        "colab_type": "code",
        "outputId": "e0548706-4563-41e3-9653-9908b45f03be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        }
      },
      "source": [
        "%%script bash\n",
        "g++ test.cpp -o test -larmadillo && ./test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------\n",
            "USER-PROVIDED MATRICES : \n",
            "------------------------------------------------------------------\n",
            "Input shape : 4 2\n",
            "Input : \n",
            "   0.1778   0.1203\n",
            "   0.0957   0.2403\n",
            "   0.1397   0.1925\n",
            "   0.2256   0.3144\n",
            "\n",
            "Target shape : 4 2\n",
            "Target : \n",
            "        0   1.0000\n",
            "   1.0000        0\n",
            "        0        0\n",
            "   1.0000        0\n",
            "\n",
            "------------------------------------------------------------------\n",
            "SUM \n",
            "------------------------------------------------------------------\n",
            "FORWARD : \n",
            "Loss : \n",
            "   0.1958   2.1178\n",
            "   2.3465   0.2748\n",
            "   0.1505   0.2138\n",
            "   1.4890   0.3775\n",
            "\n",
            "Loss (sum):\n",
            "7.16565\n",
            "BACKWARD : \n",
            "Output shape : 4 2\n",
            "Output (sum) : \n",
            "    1.2162   -8.3126\n",
            "  -10.4493    1.3163\n",
            "    1.1624    1.2384\n",
            "   -4.4326    1.4586\n",
            "\n",
            "Sum of all values in this matrix : -16.8026\n",
            "------------------------------------------------------------------\n",
            "MEAN \n",
            "------------------------------------------------------------------\n",
            "FORWARD : \n",
            "Loss (mean):\n",
            "0.895706\n",
            "BACKWARD : \n",
            "Output shape : 4 2\n",
            "Output (mean) : \n",
            "   0.1520  -1.0391\n",
            "  -1.3062   0.1645\n",
            "   0.1453   0.1548\n",
            "  -0.5541   0.1823\n",
            "\n",
            "Sum of all values in this matrix : -2.10032\n",
            "------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJm51GeT3V5P",
        "colab_type": "text"
      },
      "source": [
        "## 3 classes (Demonstrates that it works for Multi Class classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7VrlgN3k3S62"
      },
      "source": [
        "### PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Bfdhz8Xs3S63"
      },
      "source": [
        "#### None Reduction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qyhLbJlG3S64",
        "outputId": "04e4bd9d-fb3b-4c7c-c741-8579882cf871",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "loss = nn.BCELoss(reduction='none')\n",
        "input = torch.tensor([[ 0.1778,  0.1203, 0.2264],\n",
        "                      [ 0.0957,  0.2403, 0.3400],\n",
        "                      [ 0.1397,  0.1925, 0.3336], \n",
        "                      [ 0.2256,  0.3144, 0.8695]], requires_grad=True) # 4 Rows, 3 columns \n",
        "target = torch.tensor([[0., 1., 0.],\n",
        "                       [1., 0., 0.],\n",
        "                       [0., 0., 1.],\n",
        "                       [1., 0., 0.]])\n",
        "output = loss(input, target)\n",
        "output.backward(torch.ones(input.shape))\n",
        "print(\"Input : \")\n",
        "print(input)\n",
        "print(\"Target : \")\n",
        "print(target)\n",
        "print(\"FORWARD : \")\n",
        "print(\"Loss : \")\n",
        "print(output)\n",
        "print(\"BACKWARD : \")\n",
        "print(input.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : \n",
            "tensor([[0.1778, 0.1203, 0.2264],\n",
            "        [0.0957, 0.2403, 0.3400],\n",
            "        [0.1397, 0.1925, 0.3336],\n",
            "        [0.2256, 0.3144, 0.8695]], requires_grad=True)\n",
            "Target : \n",
            "tensor([[0., 1., 0.],\n",
            "        [1., 0., 0.],\n",
            "        [0., 0., 1.],\n",
            "        [1., 0., 0.]])\n",
            "FORWARD : \n",
            "Loss : \n",
            "tensor([[0.1958, 2.1178, 0.2567],\n",
            "        [2.3465, 0.2748, 0.4155],\n",
            "        [0.1505, 0.2138, 1.0978],\n",
            "        [1.4890, 0.3775, 2.0364]], grad_fn=<BinaryCrossEntropyBackward>)\n",
            "BACKWARD : \n",
            "tensor([[  1.2162,  -8.3126,   1.2927],\n",
            "        [-10.4493,   1.3163,   1.5152],\n",
            "        [  1.1624,   1.2384,  -2.9976],\n",
            "        [ -4.4326,   1.4586,   7.6628]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2qUv4wF-3S68"
      },
      "source": [
        "#### Sum Reduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MvTv3-2N3S68",
        "outputId": "3cb75584-c598-4782-eca1-08b087a1f0f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "loss = nn.BCELoss(reduction='sum')\n",
        "input = torch.tensor([[ 0.1778,  0.1203, 0.2264],\n",
        "                      [ 0.0957,  0.2403, 0.3400],\n",
        "                      [ 0.1397,  0.1925, 0.3336], \n",
        "                      [ 0.2256,  0.3144, 0.8695]], requires_grad=True) # 4 Rows, 3 columns \n",
        "target = torch.tensor([[0., 1., 0.],\n",
        "                       [1., 0., 0.],\n",
        "                       [0., 0., 1.],\n",
        "                       [1., 0., 0.]])\n",
        "output = loss(input, target)\n",
        "output.backward()\n",
        "print(\"Input : \")\n",
        "print(input)\n",
        "print(\"Target : \")\n",
        "print(target)\n",
        "print(\"FORWARD : \")\n",
        "print(\"Loss : \")\n",
        "print(output)\n",
        "print(\"BACKWARD : \")\n",
        "print(input.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : \n",
            "tensor([[0.1778, 0.1203, 0.2264],\n",
            "        [0.0957, 0.2403, 0.3400],\n",
            "        [0.1397, 0.1925, 0.3336],\n",
            "        [0.2256, 0.3144, 0.8695]], requires_grad=True)\n",
            "Target : \n",
            "tensor([[0., 1., 0.],\n",
            "        [1., 0., 0.],\n",
            "        [0., 0., 1.],\n",
            "        [1., 0., 0.]])\n",
            "FORWARD : \n",
            "Loss : \n",
            "tensor(10.9721, grad_fn=<BinaryCrossEntropyBackward>)\n",
            "BACKWARD : \n",
            "tensor([[  1.2162,  -8.3126,   1.2927],\n",
            "        [-10.4493,   1.3163,   1.5152],\n",
            "        [  1.1624,   1.2384,  -2.9976],\n",
            "        [ -4.4326,   1.4586,   7.6628]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jZmwY3j-3S6_"
      },
      "source": [
        "#### Mean reduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vpyNXSlc3S7A",
        "outputId": "612f9a8f-432d-4681-f7ce-97d0d7193cee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "loss = nn.BCELoss(reduction='mean')\n",
        "input = torch.tensor([[ 0.1778,  0.1203, 0.2264],\n",
        "                      [ 0.0957,  0.2403, 0.3400],\n",
        "                      [ 0.1397,  0.1925, 0.3336], \n",
        "                      [ 0.2256,  0.3144, 0.8695]], requires_grad=True) # 4 Rows, 3 columns \n",
        "target = torch.tensor([[0., 1., 0.],\n",
        "                       [1., 0., 0.],\n",
        "                       [0., 0., 1.],\n",
        "                       [1., 0., 0.]])\n",
        "output = loss(input, target)\n",
        "output.backward()\n",
        "print(\"Input : \")\n",
        "print(input)\n",
        "print(\"Target : \")\n",
        "print(target)\n",
        "print(\"FORWARD : \")\n",
        "print(\"Loss : \")\n",
        "print(output)\n",
        "print(\"BACKWARD : \")\n",
        "print(input.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : \n",
            "tensor([[0.1778, 0.1203, 0.2264],\n",
            "        [0.0957, 0.2403, 0.3400],\n",
            "        [0.1397, 0.1925, 0.3336],\n",
            "        [0.2256, 0.3144, 0.8695]], requires_grad=True)\n",
            "Target : \n",
            "tensor([[0., 1., 0.],\n",
            "        [1., 0., 0.],\n",
            "        [0., 0., 1.],\n",
            "        [1., 0., 0.]])\n",
            "FORWARD : \n",
            "Loss : \n",
            "tensor(0.9143, grad_fn=<BinaryCrossEntropyBackward>)\n",
            "BACKWARD : \n",
            "tensor([[ 0.1014, -0.6927,  0.1077],\n",
            "        [-0.8708,  0.1097,  0.1263],\n",
            "        [ 0.0969,  0.1032, -0.2498],\n",
            "        [-0.3694,  0.1215,  0.6386]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OmMgyLrh3S7D"
      },
      "source": [
        "### mlpack\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQYIs_t7E1tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "%%writefile test.cpp  \n",
        "\n",
        "// This uses the computations present in cross_entropy_error_impl.hpp in ann/loss_functions.\n",
        "#include <iostream>\n",
        "#include <armadillo>\n",
        "\n",
        "using namespace std;\n",
        "using namespace arma;\n",
        "\n",
        "int main()\n",
        "{\n",
        "  // Constructor\n",
        "  arma::mat x,y;\n",
        "  arma::mat weight;\n",
        "\n",
        "  x << 0.1778 << 0.1203 << 0.2264 << endr\n",
        "    << 0.0957 << 0.2403 << 0.3400 << endr\n",
        "    << 0.1397 << 0.1925 << 0.3336 << endr\n",
        "    << 0.2256 << 0.3144 << 0.8695 << endr;\n",
        "\n",
        "  y << 0 << 1 << 0 << endr\n",
        "    << 1 << 0 << 0 << endr\n",
        "    << 0 << 0 << 1 << endr\n",
        "    << 1 << 0 << 0 << endr;\n",
        " \n",
        "  // Forward\n",
        "  const double eps = 1e-10;\n",
        "  arma::mat loss_none = -(y % arma::log(x + eps) + (1. - y) % arma::log(1. - x + eps));\n",
        "  double loss_sum = arma::accu(loss_none);\n",
        "  double loss_mean = loss_sum / x.n_elem;\n",
        "\n",
        "  // Backward\n",
        "  arma::mat output;\n",
        "  output = (1. - y) / (1. - x + eps) - y / (x + eps);\n",
        "\n",
        "  // Display\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  cout << \"USER-PROVIDED MATRICES : \" << endl;\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  cout << \"Input shape : \"<< x.n_rows << \" \" << x.n_cols << endl;\n",
        "  cout << \"Input : \" << endl << x << endl;\n",
        "  cout << \"Target shape : \"<< y.n_rows << \" \" << y.n_cols << endl;\n",
        "  cout << \"Target : \" << endl << y << endl;\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  cout << \"SUM \" << endl;\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  cout << \"FORWARD : \" << endl;\n",
        "  cout << \"Loss : \\n\" << loss_none << '\\n';\n",
        "  cout << \"Loss (sum):\\n\" << loss_sum << '\\n';\n",
        "  cout << \"BACKWARD : \" << endl;\n",
        "  cout << \"Output shape : \"<< output.n_rows << \" \" << output.n_cols << endl;\n",
        "  cout << \"Output (sum) : \" << endl << output << endl;\n",
        "  cout << \"Sum of all values in this matrix : \" << arma::as_scalar(arma::accu(output)) << endl;\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  cout << \"MEAN \" << endl;\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  cout << \"FORWARD : \" << endl;\n",
        "  cout << \"Loss (mean):\\n\" << loss_mean << '\\n';\n",
        "  cout << \"BACKWARD : \" << endl;\n",
        "  cout << \"Output shape : \"<< output.n_rows << \" \" << output.n_cols << endl;\n",
        "  cout << \"Output (mean) : \" << endl << output / x.n_elem << endl;\n",
        "  cout << \"Sum of all values in this matrix : \" << arma::as_scalar(arma::accu(output / x.n_elem)) << endl;\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  return 0; \n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt9XBN1EE15K",
        "colab_type": "code",
        "outputId": "27422116-c129-402f-c762-35a16512ddcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        }
      },
      "source": [
        "%%script bash\n",
        "g++ test.cpp -o test -larmadillo && ./test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------\n",
            "USER-PROVIDED MATRICES : \n",
            "------------------------------------------------------------------\n",
            "Input shape : 4 3\n",
            "Input : \n",
            "   0.1778   0.1203   0.2264\n",
            "   0.0957   0.2403   0.3400\n",
            "   0.1397   0.1925   0.3336\n",
            "   0.2256   0.3144   0.8695\n",
            "\n",
            "Target shape : 4 3\n",
            "Target : \n",
            "        0   1.0000        0\n",
            "   1.0000        0        0\n",
            "        0        0   1.0000\n",
            "   1.0000        0        0\n",
            "\n",
            "------------------------------------------------------------------\n",
            "SUM \n",
            "------------------------------------------------------------------\n",
            "FORWARD : \n",
            "Loss : \n",
            "   0.1958   2.1178   0.2567\n",
            "   2.3465   0.2748   0.4155\n",
            "   0.1505   0.2138   1.0978\n",
            "   1.4890   0.3775   2.0364\n",
            "\n",
            "Loss (sum):\n",
            "10.9721\n",
            "BACKWARD : \n",
            "Output shape : 4 3\n",
            "Output (sum) : \n",
            "    1.2162   -8.3126    1.2927\n",
            "  -10.4493    1.3163    1.5152\n",
            "    1.1624    1.2384   -2.9976\n",
            "   -4.4326    1.4586    7.6628\n",
            "\n",
            "Sum of all values in this matrix : -9.32954\n",
            "------------------------------------------------------------------\n",
            "MEAN \n",
            "------------------------------------------------------------------\n",
            "FORWARD : \n",
            "Loss (mean):\n",
            "0.914338\n",
            "BACKWARD : \n",
            "Output shape : 4 3\n",
            "Output (mean) : \n",
            "   0.1014  -0.6927   0.1077\n",
            "  -0.8708   0.1097   0.1263\n",
            "   0.0969   0.1032  -0.2498\n",
            "  -0.3694   0.1215   0.6386\n",
            "\n",
            "Sum of all values in this matrix : -0.777462\n",
            "------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}