{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KL Div Loss",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRLe8VENOQM9",
        "colab_type": "text"
      },
      "source": [
        "# KL Divergence loss\n",
        "\n",
        "The current mlpack implementation is incorrect. <br>\n",
        "Also, the current implementation doesn't assume that ```input``` matrix has log-probabilites, unlike PyTorch. <br>\n",
        "\n",
        "This notebook fixes these issues and also introduces the different reductions that PyTorch offers. <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPWU9O3LO94x",
        "colab_type": "text"
      },
      "source": [
        "### Imports and installation of mlpack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoQR5XuyPAb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!sudo apt-get install libmlpack-dev \n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y6sYXvFs4H2k"
      },
      "source": [
        "### PyTorch\n",
        "\n",
        "The input matrix has to have log-probabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b9nbOD2FJge",
        "colab_type": "text"
      },
      "source": [
        "#### Input generation with fixed random seeds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRhoISvK-ggE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def fix_seeds(seed=0):\n",
        "  SEED = seed\n",
        "  random.seed(seed)\n",
        "  os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "  np.random.seed(SEED)\n",
        "  torch.manual_seed(SEED)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  if (torch.cuda.is_available()):\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "fix_seeds()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EEB4TKR9r6q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "830a057f-e566-44bf-ad10-15f5b33eb08f"
      },
      "source": [
        "x = torch.rand(4, 3)\n",
        "y = torch.rand(4, 3)\n",
        "xlog = torch.log(x)\n",
        "print('Input : ')\n",
        "print(xlog)\n",
        "print('Target : ')\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : \n",
            "tensor([[-0.7007, -0.2637, -2.4250],\n",
            "        [-2.0247, -1.1795, -0.4556],\n",
            "        [-0.7132, -0.1093, -0.7861],\n",
            "        [-0.4584, -1.0530, -0.9120]])\n",
            "Target : \n",
            "tensor([[0.0223, 0.1689, 0.2939],\n",
            "        [0.5185, 0.6977, 0.8000],\n",
            "        [0.1610, 0.2823, 0.6816],\n",
            "        [0.9152, 0.3971, 0.8742]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YBHd3wIt4H2l"
      },
      "source": [
        "#### None Reduction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tbvKldxa4H2m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "c75c3e95-0868-47f6-d175-c96efd4ff803"
      },
      "source": [
        "loss = torch.nn.KLDivLoss(reduction='none')\n",
        "input = torch.tensor([[-0.7007, -0.2637, -2.4250],\n",
        "                      [-2.0247, -1.1795, -0.4556],\n",
        "                      [-0.7132, -0.1093, -0.7861],\n",
        "                      [-0.4584, -1.0530, -0.9120]], requires_grad=True)\n",
        "target = torch.tensor([[0.0223, 0.1689, 0.2939],\n",
        "                      [0.5185, 0.6977, 0.8000],\n",
        "                      [0.1610, 0.2823, 0.6816],\n",
        "                      [0.9152, 0.3971, 0.8742]])\n",
        "output = loss(input, target)\n",
        "output.backward(torch.ones(input.shape))\n",
        "print(\"Input : \")\n",
        "print(input)\n",
        "print(\"Target : \")\n",
        "print(target)\n",
        "print(\"FORWARD : \")\n",
        "print(\"Loss : \")\n",
        "print(output)\n",
        "print(\"BACKWARD : \")\n",
        "print(input.grad)\n",
        "print(\"Sum of all values in this matrix for Backward: \")\n",
        "print(torch.sum(input.grad))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : \n",
            "tensor([[-0.7007, -0.2637, -2.4250],\n",
            "        [-2.0247, -1.1795, -0.4556],\n",
            "        [-0.7132, -0.1093, -0.7861],\n",
            "        [-0.4584, -1.0530, -0.9120]], requires_grad=True)\n",
            "Target : \n",
            "tensor([[0.0223, 0.1689, 0.2939],\n",
            "        [0.5185, 0.6977, 0.8000],\n",
            "        [0.1610, 0.2823, 0.6816],\n",
            "        [0.9152, 0.3971, 0.8742]])\n",
            "FORWARD : \n",
            "Loss : \n",
            "tensor([[-0.0692, -0.2558,  0.3528],\n",
            "        [ 0.7092,  0.5718,  0.1860],\n",
            "        [-0.1792, -0.3262,  0.2745],\n",
            "        [ 0.3384,  0.0514,  0.6797]], grad_fn=<KlDivBackward>)\n",
            "BACKWARD : \n",
            "tensor([[-0.0223, -0.1689, -0.2939],\n",
            "        [-0.5185, -0.6977, -0.8000],\n",
            "        [-0.1610, -0.2823, -0.6816],\n",
            "        [-0.9152, -0.3971, -0.8742]])\n",
            "Sum of all values in this matrix for Backward: \n",
            "tensor(-5.8127)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2eAofEln4H2p"
      },
      "source": [
        "#### Sum Reduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "alko8BnL4H2p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "2a3de3de-6e6f-4650-856e-1c23a27113d8"
      },
      "source": [
        "loss = torch.nn.KLDivLoss(reduction='sum')\n",
        "input = torch.tensor([[-0.7007, -0.2637, -2.4250],\n",
        "                      [-2.0247, -1.1795, -0.4556],\n",
        "                      [-0.7132, -0.1093, -0.7861],\n",
        "                      [-0.4584, -1.0530, -0.9120]], requires_grad=True)\n",
        "target = torch.tensor([[0.0223, 0.1689, 0.2939],\n",
        "                      [0.5185, 0.6977, 0.8000],\n",
        "                      [0.1610, 0.2823, 0.6816],\n",
        "                      [0.9152, 0.3971, 0.8742]])\n",
        "output = loss(input, target)\n",
        "output.backward()\n",
        "print(\"Input : \")\n",
        "print(input)\n",
        "print(\"Target : \")\n",
        "print(target)\n",
        "print(\"FORWARD : \")\n",
        "print(\"Loss : \")\n",
        "print(output)\n",
        "print(\"BACKWARD : \")\n",
        "print(input.grad)\n",
        "print(\"Sum of all values in this matrix for Backward: \")\n",
        "print(torch.sum(input.grad))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : \n",
            "tensor([[-0.7007, -0.2637, -2.4250],\n",
            "        [-2.0247, -1.1795, -0.4556],\n",
            "        [-0.7132, -0.1093, -0.7861],\n",
            "        [-0.4584, -1.0530, -0.9120]], requires_grad=True)\n",
            "Target : \n",
            "tensor([[0.0223, 0.1689, 0.2939],\n",
            "        [0.5185, 0.6977, 0.8000],\n",
            "        [0.1610, 0.2823, 0.6816],\n",
            "        [0.9152, 0.3971, 0.8742]])\n",
            "FORWARD : \n",
            "Loss : \n",
            "tensor(2.3335, grad_fn=<KlDivBackward>)\n",
            "BACKWARD : \n",
            "tensor([[-0.0223, -0.1689, -0.2939],\n",
            "        [-0.5185, -0.6977, -0.8000],\n",
            "        [-0.1610, -0.2823, -0.6816],\n",
            "        [-0.9152, -0.3971, -0.8742]])\n",
            "Sum of all values in this matrix for Backward: \n",
            "tensor(-5.8127)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vJukNLu24H2s"
      },
      "source": [
        "#### Mean reduction - Divide result of sum reduction by number of elements (will be removed in next version)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_nlOMbXC4H2t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "99e70e45-2a9a-494b-9298-8943495c02d7"
      },
      "source": [
        "# UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, \n",
        "# and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
        "\n",
        "loss = torch.nn.KLDivLoss(reduction='mean')\n",
        "input = torch.tensor([[-0.7007, -0.2637, -2.4250],\n",
        "                      [-2.0247, -1.1795, -0.4556],\n",
        "                      [-0.7132, -0.1093, -0.7861],\n",
        "                      [-0.4584, -1.0530, -0.9120]], requires_grad=True)\n",
        "target = torch.tensor([[0.0223, 0.1689, 0.2939],\n",
        "                      [0.5185, 0.6977, 0.8000],\n",
        "                      [0.1610, 0.2823, 0.6816],\n",
        "                      [0.9152, 0.3971, 0.8742]])\n",
        "output = loss(input, target)\n",
        "output.backward()\n",
        "print(\"Input : \")\n",
        "print(input)\n",
        "print(\"Target : \")\n",
        "print(target)\n",
        "print(\"FORWARD : \")\n",
        "print(\"Loss : \")\n",
        "print(output)\n",
        "print(\"BACKWARD : \")\n",
        "print(input.grad)\n",
        "print(\"Sum of all values in this matrix for Backward: \")\n",
        "print(torch.sum(input.grad))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : \n",
            "tensor([[-0.7007, -0.2637, -2.4250],\n",
            "        [-2.0247, -1.1795, -0.4556],\n",
            "        [-0.7132, -0.1093, -0.7861],\n",
            "        [-0.4584, -1.0530, -0.9120]], requires_grad=True)\n",
            "Target : \n",
            "tensor([[0.0223, 0.1689, 0.2939],\n",
            "        [0.5185, 0.6977, 0.8000],\n",
            "        [0.1610, 0.2823, 0.6816],\n",
            "        [0.9152, 0.3971, 0.8742]])\n",
            "FORWARD : \n",
            "Loss : \n",
            "tensor(0.1945, grad_fn=<KlDivBackward>)\n",
            "BACKWARD : \n",
            "tensor([[-0.0019, -0.0141, -0.0245],\n",
            "        [-0.0432, -0.0581, -0.0667],\n",
            "        [-0.0134, -0.0235, -0.0568],\n",
            "        [-0.0763, -0.0331, -0.0728]])\n",
            "Sum of all values in this matrix for Backward: \n",
            "tensor(-0.4844)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2247: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhT11JEj7RYQ",
        "colab_type": "text"
      },
      "source": [
        "#### Batch-Mean reduction - Divide result of sum reduction by number of rows (use this instead of mean)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4QENdTB7N1Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "b9c34edb-4dc2-487f-9082-6ef678338c1d"
      },
      "source": [
        "loss = torch.nn.KLDivLoss(reduction='batchmean')\n",
        "input = torch.tensor([[-0.7007, -0.2637, -2.4250],\n",
        "                      [-2.0247, -1.1795, -0.4556],\n",
        "                      [-0.7132, -0.1093, -0.7861],\n",
        "                      [-0.4584, -1.0530, -0.9120]], requires_grad=True)\n",
        "target = torch.tensor([[0.0223, 0.1689, 0.2939],\n",
        "                      [0.5185, 0.6977, 0.8000],\n",
        "                      [0.1610, 0.2823, 0.6816],\n",
        "                      [0.9152, 0.3971, 0.8742]])\n",
        "output = loss(input, target)\n",
        "output.backward()\n",
        "print(\"Input : \")\n",
        "print(input)\n",
        "print(\"Target : \")\n",
        "print(target)\n",
        "print(\"FORWARD : \")\n",
        "print(\"Loss : \")\n",
        "print(output)\n",
        "print(\"BACKWARD : \")\n",
        "print(input.grad)\n",
        "print(\"Sum of all values in this matrix for Backward: \")\n",
        "print(torch.sum(input.grad))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : \n",
            "tensor([[-0.7007, -0.2637, -2.4250],\n",
            "        [-2.0247, -1.1795, -0.4556],\n",
            "        [-0.7132, -0.1093, -0.7861],\n",
            "        [-0.4584, -1.0530, -0.9120]], requires_grad=True)\n",
            "Target : \n",
            "tensor([[0.0223, 0.1689, 0.2939],\n",
            "        [0.5185, 0.6977, 0.8000],\n",
            "        [0.1610, 0.2823, 0.6816],\n",
            "        [0.9152, 0.3971, 0.8742]])\n",
            "FORWARD : \n",
            "Loss : \n",
            "tensor(0.5834, grad_fn=<DivBackward0>)\n",
            "BACKWARD : \n",
            "tensor([[-0.0056, -0.0422, -0.0735],\n",
            "        [-0.1296, -0.1744, -0.2000],\n",
            "        [-0.0402, -0.0706, -0.1704],\n",
            "        [-0.2288, -0.0993, -0.2185]])\n",
            "Sum of all values in this matrix for Backward: \n",
            "tensor(-1.4532)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h7fZHZDk4H2w"
      },
      "source": [
        "### mlpack\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "20ckFsa14H2z"
      },
      "source": [
        "#### CURRENT IMPLEMENTATION - incorrect."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cFlCk9a64H20",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "%%writefile test.cpp  \n",
        "\n",
        "#include <iostream>\n",
        "#include <armadillo>\n",
        "\n",
        "using namespace std;\n",
        "using namespace arma;\n",
        "\n",
        "int main()\n",
        "{\n",
        "  // Constructor\n",
        "  arma::mat x,y;\n",
        "  arma::mat weight;\n",
        " \n",
        "  x << -0.7007 << -0.2637 << -2.4250 << endr\n",
        "    << -2.0247 << -1.1795 << -0.4556 << endr\n",
        "    << -0.7132 << -0.1093 << -0.7861 << endr\n",
        "    << -0.4584 << -1.0530 << -0.9120 << endr;\n",
        "\n",
        "  y << 0.0223 << 0.1689 << 0.2939 << endr\n",
        "    << 0.5185 << 0.6977 << 0.8000 << endr\n",
        "    << 0.1610 << 0.2823 << 0.6816 << endr\n",
        "    << 0.9152 << 0.3971 << 0.8742 << endr;\n",
        "\n",
        "  // Forward\n",
        "  double loss_sum = arma::accu(x % (arma::log(x) - arma::log(y)));\n",
        "  double loss_mean = arma::as_scalar(arma::mean(arma::mean(x % (arma::log(x) - arma::log(y)))));\n",
        "\n",
        "  // Backward\n",
        "  arma::mat output;\n",
        "  output = arma::accu(arma::log(x) - arma::log(y) + 1);\n",
        "\n",
        "  // Display\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  cout << \"USER-PROVIDED MATRICES : \" << endl;\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  cout << \"Input shape : \"<< x.n_rows << \" \" << x.n_cols << endl;\n",
        "  cout << \"Input : \" << endl << x << endl;\n",
        "  cout << \"Target shape : \"<< y.n_rows << \" \" << y.n_cols << endl;\n",
        "  cout << \"Target : \" << endl << y << endl;\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  cout << \"SUM \" << endl;\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  cout << \"FORWARD : \" << endl;\n",
        "  cout << \"Loss (sum):\\n\" << loss_sum << '\\n';\n",
        "  cout << \"BACKWARD : \" << endl;\n",
        "  cout << \"Output shape : \"<< output.n_rows << \" \" << output.n_cols << endl;\n",
        "  cout << \"Output (sum) : \" << endl << output << endl;\n",
        "  cout << \"Sum of all values in this matrix : \" << arma::as_scalar(arma::accu(output)) << endl;\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  cout << \"MEAN \" << endl;\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  cout << \"FORWARD : \" << endl;\n",
        "  cout << \"Loss (mean):\\n\" << loss_mean << '\\n';\n",
        "  cout << \"BACKWARD : \" << endl;\n",
        "  cout << \"Output shape : \"<< output.n_rows << \" \" << output.n_cols << endl;\n",
        "  cout << \"Output (mean) : \" << endl << arma::mean(arma::mean(arma::log(x) - arma::log(y) + 1)) << endl;\n",
        "  cout << \"Sum of all values in this matrix : \" << arma::as_scalar(arma::accu(output / x.n_elem)) << endl;\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHT34eorQquz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "748d9da3-97bb-4374-da59-a25311274895"
      },
      "source": [
        "%%script bash\n",
        "g++ test.cpp -o test -larmadillo && ./test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------\n",
            "USER-PROVIDED MATRICES : \n",
            "------------------------------------------------------------------\n",
            "Input shape : 4 3\n",
            "Input : \n",
            "  -0.7007  -0.2637  -2.4250\n",
            "  -2.0247  -1.1795  -0.4556\n",
            "  -0.7132  -0.1093  -0.7861\n",
            "  -0.4584  -1.0530  -0.9120\n",
            "\n",
            "Target shape : 4 3\n",
            "Target : \n",
            "   0.0223   0.1689   0.2939\n",
            "   0.5185   0.6977   0.8000\n",
            "   0.1610   0.2823   0.6816\n",
            "   0.9152   0.3971   0.8742\n",
            "\n",
            "------------------------------------------------------------------\n",
            "SUM \n",
            "------------------------------------------------------------------\n",
            "FORWARD : \n",
            "Loss (sum):\n",
            "nan\n",
            "BACKWARD : \n",
            "Output shape : 1 1\n",
            "Output (sum) : \n",
            "      nan\n",
            "\n",
            "Sum of all values in this matrix : nan\n",
            "------------------------------------------------------------------\n",
            "MEAN \n",
            "------------------------------------------------------------------\n",
            "FORWARD : \n",
            "Loss (mean):\n",
            "nan\n",
            "BACKWARD : \n",
            "Output shape : 1 1\n",
            "Output (mean) : \n",
            "nan\n",
            "Sum of all values in this matrix : nan\n",
            "------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svsFzAQW5pSH",
        "colab_type": "text"
      },
      "source": [
        "#### NEW IMPLEMENTATION\n",
        "\n",
        "The formula used in the Forward function matches PyTorch and TensorFlow implementations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-GL4pkn5rDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "%%writefile test.cpp  \n",
        "\n",
        "#include <iostream>\n",
        "#include <armadillo>\n",
        "\n",
        "using namespace std;\n",
        "using namespace arma;\n",
        "\n",
        "int main()\n",
        "{\n",
        "  // Constructor\n",
        "  arma::mat x,y;\n",
        "  arma::mat weight;\n",
        "  \n",
        "  x << -0.7007 << -0.2637 << -2.4250 << endr\n",
        "    << -2.0247 << -1.1795 << -0.4556 << endr\n",
        "    << -0.7132 << -0.1093 << -0.7861 << endr\n",
        "    << -0.4584 << -1.0530 << -0.9120 << endr;\n",
        "\n",
        "\n",
        "  y << 0.0223 << 0.1689 << 0.2939 << endr\n",
        "    << 0.5185 << 0.6977 << 0.8000 << endr\n",
        "    << 0.1610 << 0.2823 << 0.6816 << endr\n",
        "    << 0.9152 << 0.3971 << 0.8742 << endr;\n",
        "\n",
        "  // Forward\n",
        "  arma::mat loss_none = y % (arma::log(y) - x);\n",
        "  double loss_sum = arma::accu(loss_none);\n",
        "  double loss_mean = loss_sum / x.n_elem;\n",
        "  double loss_batch_mean = loss_sum / x.n_rows;\n",
        "\n",
        "  // Backward\n",
        "  arma::mat output;\n",
        "  output = -y ;\n",
        "\n",
        "  // Display\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  cout << \"USER-PROVIDED MATRICES : \" << endl;\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  cout << \"Input shape : \"<< x.n_rows << \" \" << x.n_cols << endl;\n",
        "  cout << \"Input : \" << endl << x << endl;\n",
        "  cout << \"Target shape : \"<< y.n_rows << \" \" << y.n_cols << endl;\n",
        "  cout << \"Target : \" << endl << y << endl;\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  cout << \"SUM \" << endl;\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  cout << \"FORWARD : \" << endl;\n",
        "  cout << \"Loss : \\n\" << loss_none << '\\n';\n",
        "  cout << \"Loss (sum):\\n\" << loss_sum << '\\n';\n",
        "  cout << \"BACKWARD : \" << endl;\n",
        "  cout << \"Output shape : \"<< output.n_rows << \" \" << output.n_cols << endl;\n",
        "  cout << \"Output (sum) : \" << endl << output << endl;\n",
        "  cout << \"Sum of all values in this matrix : \" << arma::as_scalar(arma::accu(output)) << endl;\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  cout << \"MEAN \" << endl;\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  cout << \"FORWARD : \" << endl;\n",
        "  cout << \"Loss (mean):\\n\" << loss_mean << '\\n';\n",
        "  cout << \"BACKWARD : \" << endl;\n",
        "  cout << \"Output shape : \"<< output.n_rows << \" \" << output.n_cols << endl;\n",
        "  cout << \"Output (mean) : \" << endl << output / x.n_elem << endl;\n",
        "  cout << \"Sum of all values in this matrix : \" << arma::as_scalar(arma::accu(output / x.n_elem)) << endl;\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  cout << \"BATCH - MEAN \" << endl;\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  cout << \"FORWARD : \" << endl;\n",
        "  cout << \"Loss (mean):\\n\" << loss_batch_mean << '\\n';\n",
        "  cout << \"BACKWARD : \" << endl;\n",
        "  cout << \"Output shape : \"<< output.n_rows << \" \" << output.n_cols << endl;\n",
        "  cout << \"Output (batchmean) : \" << endl << output / x.n_rows << endl;\n",
        "  cout << \"Sum of all values in this matrix : \" << arma::as_scalar(arma::accu(output / x.n_rows)) << endl;\n",
        "  cout << \"------------------------------------------------------------------\" << endl;\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_BPHb9t5rGE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f970b3ec-07bb-4e4e-fc9c-d36b974b5c62"
      },
      "source": [
        "%%script bash\n",
        "g++ test.cpp -o test -larmadillo && ./test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------\n",
            "USER-PROVIDED MATRICES : \n",
            "------------------------------------------------------------------\n",
            "Input shape : 4 3\n",
            "Input : \n",
            "  -0.7007  -0.2637  -2.4250\n",
            "  -2.0247  -1.1795  -0.4556\n",
            "  -0.7132  -0.1093  -0.7861\n",
            "  -0.4584  -1.0530  -0.9120\n",
            "\n",
            "Target shape : 4 3\n",
            "Target : \n",
            "   0.0223   0.1689   0.2939\n",
            "   0.5185   0.6977   0.8000\n",
            "   0.1610   0.2823   0.6816\n",
            "   0.9152   0.3971   0.8742\n",
            "\n",
            "------------------------------------------------------------------\n",
            "SUM \n",
            "------------------------------------------------------------------\n",
            "FORWARD : \n",
            "Loss : \n",
            "  -0.0692  -0.2558   0.3528\n",
            "   0.7092   0.5718   0.1860\n",
            "  -0.1792  -0.3262   0.2745\n",
            "   0.3384   0.0514   0.6797\n",
            "\n",
            "Loss (sum):\n",
            "2.33349\n",
            "BACKWARD : \n",
            "Output shape : 4 3\n",
            "Output (sum) : \n",
            "  -0.0223  -0.1689  -0.2939\n",
            "  -0.5185  -0.6977  -0.8000\n",
            "  -0.1610  -0.2823  -0.6816\n",
            "  -0.9152  -0.3971  -0.8742\n",
            "\n",
            "Sum of all values in this matrix : -5.8127\n",
            "------------------------------------------------------------------\n",
            "MEAN \n",
            "------------------------------------------------------------------\n",
            "FORWARD : \n",
            "Loss (mean):\n",
            "0.194458\n",
            "BACKWARD : \n",
            "Output shape : 4 3\n",
            "Output (mean) : \n",
            "  -0.0019  -0.0141  -0.0245\n",
            "  -0.0432  -0.0581  -0.0667\n",
            "  -0.0134  -0.0235  -0.0568\n",
            "  -0.0763  -0.0331  -0.0728\n",
            "\n",
            "Sum of all values in this matrix : -0.484392\n",
            "------------------------------------------------------------------\n",
            "BATCH - MEAN \n",
            "------------------------------------------------------------------\n",
            "FORWARD : \n",
            "Loss (mean):\n",
            "0.583373\n",
            "BACKWARD : \n",
            "Output shape : 4 3\n",
            "Output (batchmean) : \n",
            "  -0.0056  -0.0422  -0.0735\n",
            "  -0.1296  -0.1744  -0.2000\n",
            "  -0.0403  -0.0706  -0.1704\n",
            "  -0.2288  -0.0993  -0.2185\n",
            "\n",
            "Sum of all values in this matrix : -1.45318\n",
            "------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}